{"version":3,"file":"documentAnalysisClient.js","sourceRoot":"","sources":["../../src/documentAnalysisClient.ts"],"names":[],"mappings":"AAAA,uCAAuC;AACvC,kCAAkC;AAGlC,OAAO,EAAE,mBAAmB,EAAE,MAAM,qBAAqB,CAAC;AAE1D,OAAO,EAAE,WAAW,EAAE,MAAM,aAAa,CAAC;AAO1C,OAAO,EAAE,OAAO,EAAE,MAAM,+BAA+B,CAAC;AACxD,OAAO,EAML,4BAA4B,EAC5B,oCAAoC,GACrC,MAAM,gBAAgB,CAAC;AACxB,OAAO,EAAE,GAAG,EAAE,MAAM,mBAAmB,CAAC;AAExC,OAAO,EACL,gCAAgC,GAGjC,MAAM,uCAAuC,CAAC;AAE/C,OAAO,EAAE,iBAAiB,EAAE,OAAO,EAAE,UAAU,EAAE,MAAM,QAAQ,CAAC;AAEhE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;GA6BG;AACH,MAAM,OAAO,sBAAsB;IA+DjC,YACE,QAAgB,EAChB,UAA2C,EAC3C,UAAyC,EAAE;;QAE3C,IAAI,CAAC,WAAW,GAAG,iBAAiB,CAAC,QAAQ,EAAE,UAAU,EAAE,OAAO,CAAC,CAAC;QACpE,IAAI,CAAC,QAAQ,GAAG,mBAAmB,CAAC;YAClC,WAAW,EAAE,2BAA2B;YACxC,cAAc,EAAE,WAAW;YAC3B,SAAS,EAAE,6BAA6B;SACzC,CAAC,CAAC;QAEH,IAAI,CAAC,WAAW,GAAG,MAAA,OAAO,CAAC,UAAU,mCAAI,gCAAgC,CAAC,UAAU,CAAC;IACvF,CAAC;IAkHM,KAAK,CAAC,oBAAoB,CAC/B,KAAsC,EACtC,QAAmC,EACnC,UAA2C,EAAE;QAE7C,OAAO,IAAI,CAAC,QAAQ,CAAC,QAAQ,CAC3B,6CAA6C,EAC7C,OAAO,EACP,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,EAAE,KAAK,EAAE,QAAQ,CAAC,CACzC,CAAC;IACJ,CAAC;IAgHM,KAAK,CAAC,2BAA2B,CACtC,KAAsC,EACtC,WAAmB,EACnB,UAA2C,EAAE;QAE7C,OAAO,IAAI,CAAC,QAAQ,CAAC,QAAQ,CAC3B,oDAAoD,EACpD,OAAO,EACP,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,EAAE,KAAK,EAAE,WAAW,CAAC,CAC5C,CAAC;IACJ,CAAC;IAED;;;;;;;OAOG;IACK,OAAO,CACb,KAAsC,EACtC,KAAyC,EACzC,OAAwC;QAExC,MAAM,EACJ,OAAO,EAAE,cAAc,EACvB,UAAU,EAAE,iBAAiB,EAC7B,eAAe,GAChB,GAAG,OAAO,KAAK,KAAK,QAAQ;YAC3B,CAAC,CAAC,EAAE,OAAO,EAAE,KAAK,EAAE,UAAU,EAAE,SAAS,EAAE,eAAe,EAAE,CAAC,CAAgB,EAAE,EAAE,CAAC,CAAC,EAAE;YACrF,CAAC,CAAC,KAAK,CAAC;QAEV,IAAI,iBAAiB,IAAI,iBAAiB,KAAK,IAAI,CAAC,WAAW,EAAE;YAC/D,MAAM,IAAI,KAAK,CACb;gBACE,2DAA2D,iBAAiB,6BAA6B,IAAI,CAAC,WAAW,GAAG;gBAC5H,mEAAmE;aACpE,CAAC,IAAI,CAAC,IAAI,CAAC,CACb,CAAC;SACH;QAED,OAAO,IAAI,CAAC,oBAAoB,CAAU,KAAK,EAAE;YAC/C,cAAc;YACd,OAAO;YACP,eAAe,EAAE,CAAC,MAAM,EAAE,EAAE,CAAC,eAAe,CAAC,4BAA4B,CAAC,MAAM,CAAC,CAAC;SACnF,CAAC,CAAC;IACL,CAAC;IAED;;;;;;;;;OASG;IACK,KAAK,CAAC,oBAAoB,CAChC,KAAyC,EACzC,UAA+C;QAE/C,MAAM,EAAE,UAAU,EAAE,GAAG,UAAU,CAAC,OAAO,CAAC;QAE1C,kFAAkF;QAClF,+CAA+C;QAE/C,MAAM,gBAAgB,GAAG,CAAC,iBAAyB,EAAmC,EAAE,CACtF,IAAI,CAAC,QAAQ,CAAC,QAAQ,CACpB,8DAA8D,EAC9D,UAAU,CAAC,OAAO,EAClB,CAAC,YAAY,EAAE,EAAE,CACf,IAAI,CAAC,WAAW,CAAC,oBAAoB,CACnC;YACE,OAAO,EAAE,YAAY;SACtB,EACD;YACE,IAAI,EAAE,iBAAiB;YACvB,UAAU,EAAE,KAAK;YACjB,SAAS,EAAE;gBACT,GAAG,EAAE;oBACH,UAAU,EAAE,OAAO,CAAC,sBAAsB;iBAC3C;gBACD,OAAO,EAAE;oBACP,UAAU,EAAE,OAAO,CAAC,aAAa;iBAClC;aACF;YACD,6DAA6D;YAC7D,gBAAgB,EAAE,CAAC,OAAO,CAAC;YAC3B,UAAU,EAAE,UAAU;SACvB,CACF,CACJ,CAAC;QAEJ,MAAM,MAAM;QACV,0DAA0D;QAC1D,UAAU,KAAK,SAAS;YACtB,CAAC,CAAC,KAAK,IAAI,EAAE,CACT,IAAI,CAAC,QAAQ,CAAC,QAAQ,CACpB,oDAAoD,EACpD,UAAU,CAAC,OAAO,EAClB,KAAK,IAAI,EAAE;gBACT,MAAM,EAAE,iBAAiB,EAAE,OAAO,EAAE,GAAG,IAAI,CAAC,KAAK,CAAC,UAAU,CAG3D,CAAC;gBAEF,MAAM,MAAM,GAAG,MAAM,gBAAgB,CAAC,iBAAiB,CAAC,CAAC;gBAEzD,OAAO,oCAAoC,CACzC,UAAU,EACV,OAAO,EACP,iBAAiB,EACjB,MAAM,CACP,CAAC;YACJ,CAAC,CACF;YACL,CAAC,CAAC,iEAAiE;gBACjE,KAAK,IAAI,EAAE,CACT,IAAI,CAAC,QAAQ,CAAC,QAAQ,CACpB,mDAAmD,EACnD,UAAU,CAAC,OAAO,EAClB,KAAK,IAAI,EAAE;oBACT,MAAM,CAAC,WAAW,EAAE,cAAc,CAAC,GAAG,gBAAgB,CAAC,KAAK,CAAC,CAAC;oBAE9D,MAAM,EAAE,iBAAiB,EAAE,GAAG,MAAM,IAAI,CAAC,WAAW,CAAC,eAAe,CAClE,UAAU,CAAC,cAAc,EACzB,WAAkB,kCAEb,UAAU,CAAC,OAAO,KACrB,cAAc,IAEjB,CAAC;oBAEF,IAAI,iBAAiB,KAAK,SAAS,EAAE;wBACnC,MAAM,IAAI,KAAK,CACb,qEAAqE,CACtE,CAAC;qBACH;oBAED,MAAM,MAAM,GAAG,MAAM,gBAAgB,CAAC,iBAAiB,CAAC,CAAC;oBAEzD,OAAO,oCAAoC,CACzC,UAAU,EACV,UAAU,CAAC,cAAc,EACzB,iBAAiB,EACjB,MAAM,CACP,CAAC;gBACJ,CAAC,CACF,CAAC;QAEV,MAAM,MAAM,GAAG,MAAM,GAAG,CACtB;YACE,IAAI,EAAE,MAAM;YACZ,IAAI,EAAE,KAAK,EAAE,EAAE,iBAAiB,EAAE,OAAO,EAAE,EAAE,EAAE,CAC7C,IAAI,CAAC,QAAQ,CAAC,QAAQ,CACpB,kDAAkD,EAClD,EAAE,EACF,KAAK,IAAI,EAAE;gBACT,MAAM,MAAM,GAAG,MAAM,gBAAgB,CAAC,iBAAiB,CAAC,CAAC;gBAEzD,OAAO,oCAAoC,CACzC,UAAU,EACV,OAAO,EACP,iBAAiB,EACjB,MAAM,CACP,CAAC;YACJ,CAAC,CACF;YACH,SAAS,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAE,EAAE,EAAE,CAC5C,IAAI,CAAC,SAAS,CAAC,EAAE,OAAO,EAAE,iBAAiB,EAAE,CAAC;SACjD,EACD,UAAU,CAAC,OAAO,CAAC,kBAAkB,CACtC,CAAC;QAEF,IAAI,UAAU,CAAC,OAAO,CAAC,UAAU,KAAK,SAAS,EAAE;YAC/C,MAAM,CAAC,UAAU,CAAC,UAAU,CAAC,OAAO,CAAC,UAAU,CAAC,CAAC;YACjD,UAAU,CAAC,OAAO,CAAC,UAAU,CAAC,MAAM,CAAC,iBAAiB,EAAE,CAAC,CAAC;SAC3D;QAED,OAAO,MAAM,CAAC;IAChB,CAAC;CAGF;AAED;;;GAGG;AACH,SAAS,gBAAgB,CACvB,KAAyC;IAEzC,IAAI,OAAO,KAAK,KAAK,QAAQ,EAAE;QAC7B,OAAO;YACL,kBAAkB;YAClB;gBACE,SAAS,EAAE,KAAK;aACjB;SACF,CAAC;KACH;SAAM;QACL,OAAO,CAAC,0BAA0B,EAAE,KAAK,CAAC,CAAC;KAC5C;AACH,CAAC","sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n\nimport { KeyCredential, TokenCredential } from \"@azure/core-auth\";\nimport { createTracingClient } from \"@azure/core-tracing\";\nimport { TracingClient } from \"@azure/core-tracing\";\nimport { SDK_VERSION } from \"./constants\";\nimport {\n  AnalyzeDocumentRequest,\n  AnalyzeResultOperation,\n  ContentType,\n  GeneratedClient,\n} from \"./generated\";\nimport { accept1 } from \"./generated/models/parameters\";\nimport {\n  AnalysisOperationDefinition,\n  AnalysisPoller,\n  AnalyzeResult,\n  DocumentAnalysisPollOperationState,\n  FormRecognizerRequestBody,\n  toAnalyzeResultFromGenerated,\n  toDocumentAnalysisPollOperationState,\n} from \"./lro/analysis\";\nimport { lro } from \"./lro/util/poller\";\nimport { AnalyzeDocumentOptions } from \"./options/AnalyzeDocumentsOptions\";\nimport {\n  DEFAULT_GENERATED_CLIENT_OPTIONS,\n  DocumentAnalysisClientOptions,\n  FormRecognizerApiVersion,\n} from \"./options/FormRecognizerClientOptions\";\nimport { DocumentModel } from \"./documentModel\";\nimport { makeServiceClient, Mappers, SERIALIZER } from \"./util\";\n\n/**\n * A client for interacting with the Form Recognizer service's analysis features.\n *\n * ### Examples:\n *\n * The Form Recognizer service and clients support two means of authentication:\n *\n * #### Azure Active Directory\n *\n * ```javascript\n * import { DocumentAnalysisClient } from \"@azure/ai-form-recognizer\";\n * import { DefaultAzureCredential } from \"@azure/identity\";\n *\n * const endpoint = \"https://<resource name>.cognitiveservices.azure.com\";\n * const credential = new DefaultAzureCredential();\n *\n * const client = new DocumentAnalysisClient(endpoint, credential);\n * ```\n *\n * #### API Key (Subscription Key)\n *\n * ```javascript\n * import { DocumentAnalysisClient, AzureKeyCredential } from \"@azure/ai-form-recognizer\";\n *\n * const endpoint = \"https://<resource name>.cognitiveservices.azure.com\";\n * const credential = new AzureKeyCredential(\"<api key>\");\n *\n * const client = new DocumentAnalysisClient(endpoint, credential);\n * ```\n */\nexport class DocumentAnalysisClient {\n  private _restClient: GeneratedClient;\n  private _tracing: TracingClient;\n  private _apiVersion: FormRecognizerApiVersion;\n\n  /**\n   * Create a `DocumentAnalysisClient` instance from a resource endpoint and a an Azure Identity `TokenCredential`.\n   *\n   * See the [`@azure/identity`](https://npmjs.com/package/\\@azure/identity) package for more information about\n   * authenticating with Azure Active Directory.\n   *\n   * ### Example:\n   *\n   * ```javascript\n   * import { DocumentAnalysisClient } from \"@azure/ai-form-recognizer\";\n   * import { DefaultAzureCredential } from \"@azure/identity\";\n   *\n   * const endpoint = \"https://<resource name>.cognitiveservices.azure.com\";\n   * const credential = new DefaultAzureCredential();\n   *\n   * const client = new DocumentAnalysisClient(endpoint, credential);\n   * ```\n   *\n   * @param endpoint - the endpoint URL of an Azure Cognitive Services instance\n   * @param credential - a TokenCredential instance from the `@azure/identity` package\n   * @param options - optional settings for configuring all methods in the client\n   */\n  public constructor(\n    endpoint: string,\n    credential: TokenCredential,\n    options?: DocumentAnalysisClientOptions\n  );\n  /**\n   * Create a `DocumentAnalysisClient` instance from a resource endpoint and a static API key (`KeyCredential`),\n   *\n   * ### Example:\n   *\n   * ```javascript\n   * import { DocumentAnalysisClient, AzureKeyCredential } from \"@azure/ai-form-recognizer\";\n   *\n   * const endpoint = \"https://<resource name>.cognitiveservices.azure.com\";\n   * const credential = new AzureKeyCredential(\"<api key>\");\n   *\n   * const client = new DocumentAnalysisClient(endpoint, credential);\n   * ```\n   *\n   * @param endpoint - the endpoint URL of an Azure Cognitive Services instance\n   * @param credential - a KeyCredential containing the Cognitive Services instance subscription key\n   * @param options - optional settings for configuring all methods in the client\n   */\n  public constructor(\n    endpoint: string,\n    credential: KeyCredential,\n    options?: DocumentAnalysisClientOptions\n  );\n  /**\n   * @hidden\n   */\n  public constructor(\n    endpoint: string,\n    credential: KeyCredential | TokenCredential,\n    options?: DocumentAnalysisClientOptions\n  );\n  public constructor(\n    endpoint: string,\n    credential: KeyCredential | TokenCredential,\n    options: DocumentAnalysisClientOptions = {}\n  ) {\n    this._restClient = makeServiceClient(endpoint, credential, options);\n    this._tracing = createTracingClient({\n      packageName: \"@azure/ai-form-recognizer\",\n      packageVersion: SDK_VERSION,\n      namespace: \"Microsoft.CognitiveServices\",\n    });\n\n    this._apiVersion = options.apiVersion ?? DEFAULT_GENERATED_CLIENT_OPTIONS.apiVersion;\n  }\n\n  // #region Analysis\n\n  /**\n   * Extract data from an input using a model given by its unique ID.\n   *\n   * This operation supports custom as well as prebuilt models. For example, to use the prebuilt invoice model, provide\n   * the model ID \"prebuilt-invoice\", or to use the simpler prebuilt layout model, provide the model ID\n   * \"prebuilt-layout\".\n   *\n   * The fields produced in the `AnalyzeResult` depend on the model that is used for analysis, and the values in any\n   * extracted documents' fields depend on the document types in the model (if any) and their corresponding field\n   * schemas.\n   *\n   * ### Examples\n   *\n   * This method supports streamable request bodies ({@link FormRecognizerRequestBody}) such as Node.JS `ReadableStream`\n   * objects, browser `Blob`s, and `ArrayBuffer`s. The contents of the body will be uploaded to the service for analysis.\n   *\n   * ```javascript\n   * import * as fs from \"fs\";\n   *\n   * const file = fs.createReadStream(\"path/to/receipt.pdf\");\n   *\n   * // The model that is passed to the following function call determines the type of the eventual result. In the\n   * // example, we will use the prebuilt receipt model, but you could use a custom model ID/name instead.\n   * const poller = await client.beginAnalyzeDocument(\"prebuilt-receipt\", file);\n   *\n   * // The result is a long-running operation (poller), which must itself be polled until the operation completes\n   * const {\n   *   pages, // pages extracted from the document, which contain lines and words\n   *   tables, // extracted tables, organized into cells that contain their contents\n   *   styles, // text styles (ex. handwriting) that were observed in the document\n   *   keyValuePairs, // extracted pairs of elements  (directed associations from one element in the input to another)\n   *   entities, // extracted entities in the input's content, which are categorized (ex. \"Location\" or \"Organization\")\n   *   documents // extracted documents (instances of one of the model's document types and its field schema)\n   * } = await poller.pollUntilDone();\n   *\n   * // Extract the fields of the first document. These fields constitute a receipt, because we used the receipt model\n   * const [{ fields: receipt }] = documents;\n   *\n   * // The fields correspond to the model's document types and their field schemas. Refer to the Form Recognizer\n   * // documentation for information about the document types and field schemas within a model, or use the `getModel`\n   * // operation to view this information programmatically.\n   * console.log(\"The type of this receipt is:\", receipt?.[\"ReceiptType\"]?.value);\n   * ```\n   *\n   *\n   * @param modelId - the unique ID (name) of the model within this client's resource\n   * @param document - a {@link FormRecognizerRequestBody} that will be uploaded with the request\n   * @param options - optional settings for the analysis operation and poller\n   * @returns a long-running operation (poller) that will eventually produce an `AnalyzeResult`\n   */\n  public async beginAnalyzeDocument(\n    modelId: string,\n    document: FormRecognizerRequestBody,\n    // eslint-disable-next-line @azure/azure-sdk/ts-naming-options\n    options?: AnalyzeDocumentOptions\n  ): Promise<AnalysisPoller>;\n  /**\n   * Extract data from an input using a model that has a known, strongly-typed document schema (a {@link DocumentModel}).\n   *\n   * The fields produced in the `AnalyzeResult` depend on the model that is used for analysis. In TypeScript, the type\n   * of the result for this method overload is inferred from the type of the input `DocumentModel`.\n   *\n   * ### Examples\n   *\n   * This method supports streamable request bodies ({@link FormRecognizerRequestBody}) such as Node.JS `ReadableStream`\n   * objects, browser `Blob`s, and `ArrayBuffer`s. The contents of the body will be uploaded to the service for analysis.\n   *\n   * ```typescript\n   * import * as fs from \"fs\";\n   *\n   * // See the `prebuilt` folder in the SDK samples (http://aka.ms/azsdk/formrecognizer/js/samples) for examples of\n   * // DocumentModels for known prebuilts.\n   * import { PrebuiltReceiptModel } from \"./prebuilt-receipt.ts\";\n   *\n   * const file = fs.createReadStream(\"path/to/receipt.pdf\");\n   *\n   * // The model that is passed to the following function call determines the type of the eventual result. In the\n   * // example, we will use the prebuilt receipt model.\n   * const poller = await client.beginAnalyzeDocument(PrebuiltReceiptModel, file);\n   *\n   * // The result is a long-running operation (poller), which must itself be polled until the operation completes\n   * const {\n   *   pages, // pages extracted from the document, which contain lines and words\n   *   tables, // extracted tables, organized into cells that contain their contents\n   *   styles, // text styles (ex. handwriting) that were observed in the document\n   *   keyValuePairs, // extracted pairs of elements  (directed associations from one element in the input to another)\n   *\n   *   documents // extracted documents (instances of one of the model's document types and its field schema)\n   * } = await poller.pollUntilDone();\n   *\n   * // Extract the fields of the first document. These fields constitute a receipt, because we used the receipt model\n   * const [{ fields: receipt }] = documents;\n   *\n   * // Since we used the strongly-typed PrebuiltReceiptModel object instead of the \"prebuilt-receipt\" model ID\n   * // string, the fields of the receipt are strongly-typed and have camelCase names (as opposed to PascalCase).\n   * console.log(\"The type of this receipt is:\", receipt.receiptType?.value);\n   * ```\n   *\n   * @param model - a {@link DocumentModel} representing the model to use for analysis and the expected output type\n   * @param document - a {@link FormRecognizerRequestBody} that will be uploaded with the request\n   * @param options - optional settings for the analysis operation and poller\n   * @returns a long-running operation (poller) that will eventually produce an `AnalyzeResult` with documents that have\n   *          the result type associated with the input model\n   */\n  public async beginAnalyzeDocument<Result>(\n    model: DocumentModel<Result>,\n    document: FormRecognizerRequestBody,\n    // eslint-disable-next-line @azure/azure-sdk/ts-naming-options\n    options?: AnalyzeDocumentOptions<Result>\n  ): Promise<AnalysisPoller<Result>>;\n  public async beginAnalyzeDocument(\n    model: string | DocumentModel<unknown>,\n    document: FormRecognizerRequestBody,\n    options: AnalyzeDocumentOptions<unknown> = {}\n  ): Promise<AnalysisPoller<unknown>> {\n    return this._tracing.withSpan(\n      \"DocumentAnalysisClient.beginAnalyzeDocument\",\n      options,\n      this.analyze.bind(this, model, document)\n    );\n  }\n\n  /**\n   * Extract data from an input using a model given by its unique ID.\n   *\n   * This operation supports custom as well as prebuilt models. For example, to use the prebuilt invoice model, provide\n   * the model ID \"prebuilt-invoice\", or to use the simpler prebuilt layout model, provide the model ID\n   * \"prebuilt-layout\".\n   *\n   * The fields produced in the `AnalyzeResult` depend on the model that is used for analysis, and the values in any\n   * extracted documents' fields depend on the document types in the model (if any) and their corresponding field\n   * schemas.\n   *\n   * ### Examples\n   *\n   * This method supports extracting data from a file at a given URL. The Form Recognizer service will attempt to\n   * download a file using the submitted URL, so the URL must be accessible from the public internet. For example, a SAS\n   * token can be used to grant read access to a blob in Azure Storage, and the service will use the SAS-encoded URL to\n   * request the file.\n   *\n   * ```javascript\n   * // the URL must be publicly accessible\n   * const url = \"<receipt document url>\";\n   *\n   * // The model that is passed to the following function call determines the type of the eventual result. In the\n   * // example, we will use the prebuilt receipt model, but you could use a custom model ID/name instead.\n   * const poller = await client.beginAnalyzeDocument(\"prebuilt-receipt\", url);\n   *\n   * // The result is a long-running operation (poller), which must itself be polled until the operation completes\n   * const {\n   *   pages, // pages extracted from the document, which contain lines and words\n   *   tables, // extracted tables, organized into cells that contain their contents\n   *   styles, // text styles (ex. handwriting) that were observed in the document\n   *   keyValuePairs, // extracted pairs of elements  (directed associations from one element in the input to another)\n   *\n   *   documents // extracted documents (instances of one of the model's document types and its field schema)\n   * } = await poller.pollUntilDone();\n   *\n   * // Extract the fields of the first document. These fields constitute a receipt, because we used the receipt model\n   * const [{ fields: receipt }] = documents;\n   *\n   * // The fields correspond to the model's document types and their field schemas. Refer to the Form Recognizer\n   * // documentation for information about the document types and field schemas within a model, or use the `getModel`\n   * // operation to view this information programmatically.\n   * console.log(\"The type of this receipt is:\", receipt?.[\"ReceiptType\"]?.value);\n   * ```\n   *\n   * @param modelId - the unique ID (name) of the model within this client's resource\n   * @param documentUrl - a URL (string) to an input document accessible from the public internet\n   * @param options - optional settings for the analysis operation and poller\n   * @returns a long-running operation (poller) that will eventually produce an `AnalyzeResult`\n   */\n  public async beginAnalyzeDocumentFromUrl(\n    modelId: string,\n    documentUrl: string,\n    // eslint-disable-next-line @azure/azure-sdk/ts-naming-options\n    options?: AnalyzeDocumentOptions\n  ): Promise<AnalysisPoller>;\n  /**\n   * Extract data from an input using a model that has a known, strongly-typed document schema (a {@link DocumentModel}).\n   *\n   * The fields produced in the `AnalyzeResult` depend on the model that is used for analysis. In TypeScript, the type\n   * of the result for this method overload is inferred from the type of the input `DocumentModel`.\n   *\n   * ### Examples\n   *\n   * This method supports extracting data from a file at a given URL. The Form Recognizer service will attempt to\n   * download a file using the submitted URL, so the URL must be accessible from the public internet. For example, a SAS\n   * token can be used to grant read access to a blob in Azure Storage, and the service will use the SAS-encoded URL to\n   * request the file.\n   *\n   * ```typescript\n   * // See the `prebuilt` folder in the SDK samples (http://aka.ms/azsdk/formrecognizer/js/samples) for examples of\n   * // DocumentModels for known prebuilts.\n   * import { PrebuiltReceiptModel } from \"./prebuilt-receipt.ts\";\n   *\n   * // the URL must be publicly accessible\n   * const url = \"<receipt document url>\";\n   *\n   * // The model that is passed to the following function call determines the type of the eventual result. In the\n   * // example, we will use the prebuilt receipt model.\n   * const poller = await client.beginAnalyzeDocument(PrebuiltReceiptModel, url);\n   *\n   * // The result is a long-running operation (poller), which must itself be polled until the operation completes\n   * const {\n   *   pages, // pages extracted from the document, which contain lines and words\n   *   tables, // extracted tables, organized into cells that contain their contents\n   *   styles, // text styles (ex. handwriting) that were observed in the document\n   *   keyValuePairs, // extracted pairs of elements  (directed associations from one element in the input to another)\n   *\n   *   documents // extracted documents (instances of one of the model's document types and its field schema)\n   * } = await poller.pollUntilDone();\n   *\n   * // Extract the fields of the first document. These fields constitute a receipt, because we used the receipt model\n   * const [{ fields: receipt }] = documents;\n   *\n   * // Since we used the strongly-typed PrebuiltReceiptModel object instead of the \"prebuilt-receipt\" model ID\n   * // string, the fields of the receipt are strongly-typed and have camelCase names (as opposed to PascalCase).\n   * console.log(\"The type of this receipt is:\", receipt.receiptType?.value);\n   * ```\n   *\n   * @param model - a {@link DocumentModel} representing the model to use for analysis and the expected output type\n   * @param documentUrl - a URL (string) to an input document accessible from the public internet\n   * @param options - optional settings for the analysis operation and poller\n   * @returns a long-running operation (poller) that will eventually produce an `AnalyzeResult`\n   */\n  public async beginAnalyzeDocumentFromUrl<Result>(\n    model: DocumentModel<Result>,\n    documentUrl: string,\n    // eslint-disable-next-line @azure/azure-sdk/ts-naming-options\n    options?: AnalyzeDocumentOptions<Result>\n  ): Promise<AnalysisPoller<Result>>;\n  public async beginAnalyzeDocumentFromUrl(\n    model: string | DocumentModel<unknown>,\n    documentUrl: string,\n    options: AnalyzeDocumentOptions<unknown> = {}\n  ): Promise<AnalysisPoller<unknown>> {\n    return this._tracing.withSpan(\n      \"DocumentAnalysisClient.beginAnalyzeDocumentFromUrl\",\n      options,\n      this.analyze.bind(this, model, documentUrl)\n    );\n  }\n\n  /**\n   * A helper method for running analysis polymorphically.\n   * @internal\n   * @param model - the model ID or DocumentModel to use for analysis\n   * @param input - the string URL or request body to use\n   * @param options - analysis options\n   * @returns - an analysis poller\n   */\n  private analyze(\n    model: string | DocumentModel<unknown>,\n    input: string | FormRecognizerRequestBody,\n    options: AnalyzeDocumentOptions<unknown>\n  ) {\n    const {\n      modelId: initialModelId,\n      apiVersion: requestApiVersion,\n      transformResult,\n    } = typeof model === \"string\"\n      ? { modelId: model, apiVersion: undefined, transformResult: (v: AnalyzeResult) => v }\n      : model;\n\n    if (requestApiVersion && requestApiVersion !== this._apiVersion) {\n      throw new Error(\n        [\n          `API Version mismatch: the provided model wants version: ${requestApiVersion}, but the client is using ${this._apiVersion}.`,\n          \"The API version of the model must match the client's API version.\",\n        ].join(\"\\n\")\n      );\n    }\n\n    return this.createAnalysisPoller<unknown>(input, {\n      initialModelId,\n      options,\n      transformResult: (result) => transformResult(toAnalyzeResultFromGenerated(result)),\n    });\n  }\n\n  /**\n   * Create an LRO poller that handles analysis operations.\n   *\n   * This is the meat of all analysis polling operations.\n   *\n   * @param input - either a string for URL inputs or a FormRecognizerRequestBody to upload a file directly to the Form\n   *                Recognizer API\n   * @param definition - operation definition (initial model ID, operation transforms, request options)\n   * @returns - an analysis poller that produces the given return types according to the operation spec\n   */\n  private async createAnalysisPoller<Result>(\n    input: string | FormRecognizerRequestBody,\n    definition: AnalysisOperationDefinition<Result>\n  ): Promise<AnalysisPoller<Result>> {\n    const { resumeFrom } = definition.options;\n\n    // TODO: what should we do if resumeFrom.modelId is different from initialModelId?\n    // And what do we do with the redundant input??\n\n    const getAnalyzeResult = (operationLocation: string): Promise<AnalyzeResultOperation> =>\n      this._tracing.withSpan(\n        \"DocumentAnalysisClient.createAnalysisPoller-getAnalyzeResult\",\n        definition.options,\n        (finalOptions) =>\n          this._restClient.sendOperationRequest<AnalyzeResultOperation>(\n            {\n              options: finalOptions,\n            },\n            {\n              path: operationLocation,\n              httpMethod: \"GET\",\n              responses: {\n                200: {\n                  bodyMapper: Mappers.AnalyzeResultOperation,\n                },\n                default: {\n                  bodyMapper: Mappers.ErrorResponse,\n                },\n              },\n              // URL is fully-formed, so we don't need any query parameters\n              headerParameters: [accept1],\n              serializer: SERIALIZER,\n            }\n          )\n      );\n\n    const toInit =\n      // If the user gave us a stored token, we'll poll it again\n      resumeFrom !== undefined\n        ? async () =>\n            this._tracing.withSpan(\n              \"DocumentAnalysisClient.createAnalysisPoller-resume\",\n              definition.options,\n              async () => {\n                const { operationLocation, modelId } = JSON.parse(resumeFrom) as {\n                  operationLocation: string;\n                  modelId: string;\n                };\n\n                const result = await getAnalyzeResult(operationLocation);\n\n                return toDocumentAnalysisPollOperationState(\n                  definition,\n                  modelId,\n                  operationLocation,\n                  result\n                );\n              }\n            )\n        : // Otherwise, we'll start a new operation from the initialModelId\n          async () =>\n            this._tracing.withSpan(\n              \"DocumentAnalysisClient.createAnalysisPoller-start\",\n              definition.options,\n              async () => {\n                const [contentType, analyzeRequest] = toAnalyzeRequest(input);\n\n                const { operationLocation } = await this._restClient.analyzeDocument(\n                  definition.initialModelId,\n                  contentType as any,\n                  {\n                    ...definition.options,\n                    analyzeRequest,\n                  }\n                );\n\n                if (operationLocation === undefined) {\n                  throw new Error(\n                    \"Unable to start analysis operation: no Operation-Location received.\"\n                  );\n                }\n\n                const result = await getAnalyzeResult(operationLocation);\n\n                return toDocumentAnalysisPollOperationState(\n                  definition,\n                  definition.initialModelId,\n                  operationLocation,\n                  result\n                );\n              }\n            );\n\n    const poller = await lro<Result, DocumentAnalysisPollOperationState<Result>>(\n      {\n        init: toInit,\n        poll: async ({ operationLocation, modelId }) =>\n          this._tracing.withSpan(\n            \"DocumentAnalysisClient.createAnalysisPoller-poll\",\n            {},\n            async () => {\n              const result = await getAnalyzeResult(operationLocation);\n\n              return toDocumentAnalysisPollOperationState(\n                definition,\n                modelId,\n                operationLocation,\n                result\n              );\n            }\n          ),\n        serialize: ({ operationLocation, modelId }) =>\n          JSON.stringify({ modelId, operationLocation }),\n      },\n      definition.options.updateIntervalInMs\n    );\n\n    if (definition.options.onProgress !== undefined) {\n      poller.onProgress(definition.options.onProgress);\n      definition.options.onProgress(poller.getOperationState());\n    }\n\n    return poller;\n  }\n\n  // #endregion\n}\n\n/**\n * Produce an appropriate pair of content-type and analyzeRequest value for the analysis request.\n * @internal\n */\nfunction toAnalyzeRequest(\n  input: string | FormRecognizerRequestBody\n): [\"application/json\", AnalyzeDocumentRequest] | [ContentType, FormRecognizerRequestBody] {\n  if (typeof input === \"string\") {\n    return [\n      \"application/json\",\n      {\n        urlSource: input,\n      },\n    ];\n  } else {\n    return [\"application/octet-stream\", input];\n  }\n}\n"]}